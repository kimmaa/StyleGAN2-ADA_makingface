{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hispanic_StyleGAN2-ada_Group3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bql5bZLfsjkc"
      },
      "source": [
        "# Hispanic image 생성 StyleGAN2-ADA \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI_i1MwgpzOD"
      },
      "source": [
        "StyleGAN2-ADA only work with Tensorflow 1. Run the next cell before anything \n",
        "\n",
        "else to make sure we’re using TF1 and not TF2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKYAU7Wub3WW"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG9YnXPQmalc",
        "outputId": "1914d5f5-5484-48fa-9910-812e4a8f663d"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Nov  7 06:37:32 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YcUMPQp6ipP"
      },
      "source": [
        "## Install Repo to Google Drive\n",
        "\n",
        "Colab is a little funky with training. I’ve found the best way to do this is to install the repo directly into your Google Drive folder.\n",
        "\n",
        "First, mount your Drive to the Colab notebook: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxxYlEKI9Gis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54a2817d-81cd-492f-aa69-cd5dd85b65a4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epV6TDzAjox1"
      },
      "source": [
        "Next, run this cell. If you’re already installed the repo, it will skip the installation process and change into the repo’s directory. If you haven’t installed it, it will install all the files necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HX77jscX2zV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd455398-bb07-4e86-8b97-489cde1fc5fe"
      },
      "source": [
        "import os\n",
        "if os.path.isdir(\"./AIB_04_Stylebot/colab-sg2-ada\"):\n",
        "    %cd \"./AIB_04_Stylebot/colab-sg2-ada/stylegan2-ada\"\n",
        "else:\n",
        "    #install script\n",
        "    %cd \"/content/drive/MyDrive/AIB_04_Stylebot\"\n",
        "    !mkdir colab-sg2-ada\n",
        "    %cd colab-sg2-ada\n",
        "    !git clone https://github.com/dvschultz/stylegan2-ada\n",
        "    %cd stylegan2-ada\n",
        "    !mkdir downloads\n",
        "    !mkdir datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1zQGyqDeW63FEr3sXvFz23SVnqvoGEBUd/AIB_04_Stylebot/colab-sg2-ada/stylegan2-ada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hSjM8apL08B"
      },
      "source": [
        "import cv2\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from google.colab import files\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import imageio\n",
        "import os\n",
        "from pathlib import Path\n",
        "import glob\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG_ir2s_Lpdn"
      },
      "source": [
        "# 1024 *1024 resize\n",
        "\n",
        "result_path = './AIB_04_Stylebot/selected_crop_photo'\n",
        "\n",
        "image_files = Path(result_path)\n",
        "image_files = list(image_files.glob(r'*.jpg'))\n",
        "\n",
        "for name in image_files[:]:\n",
        "  img = cv2.imread(f'{name}')\n",
        "  img = cv2.resize(img, (1024,1024))\n",
        "\n",
        "  # 전처리 이미지 저장\n",
        "  print(img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeS9tDvt61VG"
      },
      "source": [
        "## Convert dataset to .tfrecords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FNnFqBFtnTE"
      },
      "source": [
        "수집한 이미지 데이터를 .tfrecords 파일로 변환해 주는 코드입니다.\n",
        "* 데이터셋에서 한번만 작동하면 됩니다. \n",
        "* tfrecords\n",
        "=TFRecord는 데이터 세트의 포맷의 하나로 TFRecord형식은 바이너리 코드의 시리즈를 저장하기 위한 단순한 형식 ==> 대규모 데이터를 효율적으로 학습할 수 있게 해줍니다.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-BZHhBe7AvO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b46b7547-7deb-4984-9065-d8af3c8c30d2"
      },
      "source": [
        "#you don't need to edit anything here\n",
        "!python dataset_tool.py create_from_images ./stylegan2-ada/datasets/{'1024image'} {result_path}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n",
            "Loading images from \"/content/drive/MyDrive/AIB_04_Stylebot/selected_crop\"\n",
            "Creating dataset \"/content/drive/MyDrive/AIB_04_Stylebot/colab-sg2-ada/stylegan2-ada/datasets/1024image\"\n",
            "dataset_tool.py:97: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
            "  'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[quant.tostring()]))}))\n",
            "Added 55 images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DvTupHzP2s_"
      },
      "source": [
        "## Train a custom model\n",
        "* 모델 학습\n",
        "* pretrained dataset = ffhq1024를 사용 했습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOftFoyiDU3s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f078f685-cc2c-4698-c9a0-24c4d9ccab58"
      },
      "source": [
        "# dataset_name만 바꾸고 진행했습니다.\n",
        "\n",
        "#this name must EXACTLY match the dataset name you used when creating the .tfrecords file\n",
        "dataset_name = \"new_image\"\n",
        "#how often should the model generate samples and a .pkl file\n",
        "snapshot_count = 4\n",
        "#should the images be mirrored left to right?\n",
        "mirrored = True\n",
        "#should the images be mirrored top to bottom?\n",
        "mirroredY = False\n",
        "#metrics? \n",
        "metric_list = None\n",
        "#augments\n",
        "augs = \"bgc\"\n",
        "\n",
        "#\n",
        "# this is the most important cell to update\n",
        "#\n",
        "# running it for the first time? set it to ffhq(+resolution)\n",
        "# resuming? get the path to your latest .pkl file and use that\n",
        "resume_from = \"ffhq1024\"\n",
        "\n",
        "# model training\n",
        "!python train.py --outdir ./results --snap={snapshot_count} --cfg=stylegan2 --kimg=100 --data=./datasets/{dataset_name} --augpipe={augs} --mirror={mirrored} --mirrory={mirroredY} --metrics={metric_list} --resume={resume_from}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x558350a92000 @  0x7f97f48ce001 0x7f97f1ad154f 0x7f97f1b21b58 0x7f97f1b25b17 0x7f97f1bc4203 0x558349a22544 0x558349a22240 0x558349a96627 0x558349a90ced 0x558349a2448c 0x558349a65159 0x558349a620a4 0x558349a22d49 0x558349a9694f 0x558349a909ee 0x558349962e2b 0x558349a92fe4 0x558349a909ee 0x558349962e2b 0x558349a92fe4 0x558349a90ced 0x558349962e2b 0x558349a92fe4 0x558349a23afa 0x558349a91915 0x558349a909ee 0x558349a906f3 0x558349b5a4c2 0x558349b5a83d 0x558349b5a6e6 0x558349b32163\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x558450a92000 @  0x7f97f48cc1e7 0x7f97f1ad146e 0x7f97f1b21c7b 0x7f97f1b2235f 0x7f97f1bc4103 0x558349a22544 0x558349a22240 0x558349a96627 0x558349a909ee 0x558349a23bda 0x558349a92737 0x558349a909ee 0x558349a23bda 0x558349a92737 0x558349a909ee 0x558349a23bda 0x558349a92737 0x558349a23afa 0x558349a91915 0x558349a909ee 0x558349a23bda 0x558349a95d00 0x558349a909ee 0x558349a23bda 0x558349a92737 0x558349a90ced 0x558349a2448c 0x558349a65159 0x558349a620a4 0x558349a22d49 0x558349a9694f\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x558552342000 @  0x7f97f48cc1e7 0x7f97f1ad146e 0x7f97f1b21c7b 0x7f97f1b2235f 0x7f979d4d1235 0x7f979ce54792 0x7f979ce54d42 0x7f979ce0daee 0x558349a22437 0x558349a22240 0x558349a960f3 0x558349a23afa 0x558349a91c0d 0x558349a90ced 0x558349962eb0 0x558349a92fe4 0x558349a909ee 0x558349a23bda 0x558349a91c0d 0x558349a90ced 0x558349a23bda 0x558349a91c0d 0x558349a23afa 0x558349a91c0d 0x558349a909ee 0x558349a24271 0x558349a24698 0x558349a92fe4 0x558349a909ee 0x558349a23bda 0x558349a91915\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_args\": {\n",
            "    \"func_name\": \"training.networks.G_main\",\n",
            "    \"fmap_base\": 16384,\n",
            "    \"fmap_max\": 512,\n",
            "    \"mapping_layers\": 8,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"D_args\": {\n",
            "    \"func_name\": \"training.networks.D_main\",\n",
            "    \"mbstd_group_size\": 4,\n",
            "    \"fmap_base\": 16384,\n",
            "    \"fmap_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_args\": {\n",
            "    \"beta1\": 0.0,\n",
            "    \"beta2\": 0.99,\n",
            "    \"learning_rate\": 0.002\n",
            "  },\n",
            "  \"D_opt_args\": {\n",
            "    \"beta1\": 0.0,\n",
            "    \"beta2\": 0.99,\n",
            "    \"learning_rate\": 0.002\n",
            "  },\n",
            "  \"loss_args\": {\n",
            "    \"func_name\": \"training.loss.stylegan2\",\n",
            "    \"r1_gamma\": 10\n",
            "  },\n",
            "  \"augment_args\": {\n",
            "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
            "    \"tune_heuristic\": \"rt\",\n",
            "    \"tune_target\": 0.6,\n",
            "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
            "    \"apply_args\": {\n",
            "      \"xflip\": 1,\n",
            "      \"rotate90\": 1,\n",
            "      \"xint\": 1,\n",
            "      \"scale\": 1,\n",
            "      \"rotate\": 1,\n",
            "      \"aniso\": 1,\n",
            "      \"xfrac\": 1,\n",
            "      \"brightness\": 1,\n",
            "      \"contrast\": 1,\n",
            "      \"lumaflip\": 1,\n",
            "      \"hue\": 1,\n",
            "      \"saturation\": 1\n",
            "    },\n",
            "    \"tune_kimg\": 100\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 4,\n",
            "  \"network_snapshot_ticks\": 4,\n",
            "  \"train_dataset_args\": {\n",
            "    \"path\": \"./datasets/new_image\",\n",
            "    \"max_label_size\": 0,\n",
            "    \"use_raw\": false,\n",
            "    \"resolution\": 512,\n",
            "    \"mirror_augment\": true,\n",
            "    \"mirror_augment_v\": false\n",
            "  },\n",
            "  \"metric_arg_list\": [],\n",
            "  \"metric_dataset_args\": {\n",
            "    \"path\": \"./datasets/new_image\",\n",
            "    \"max_label_size\": 0,\n",
            "    \"use_raw\": false,\n",
            "    \"resolution\": 512,\n",
            "    \"mirror_augment\": true,\n",
            "    \"mirror_augment_v\": false\n",
            "  },\n",
            "  \"total_kimg\": 100,\n",
            "  \"minibatch_size\": 32,\n",
            "  \"minibatch_gpu\": 4,\n",
            "  \"G_smoothing_kimg\": 10,\n",
            "  \"G_smoothing_rampup\": null,\n",
            "  \"resume_pkl\": \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/transfer-learning-source-nets/ffhq-res1024-mirror-stylegan2-noaug.pkl\",\n",
            "  \"run_dir\": \"./results/00013-new_image-mirror-stylegan2-kimg100-bgc-resumeffhq1024\"\n",
            "}\n",
            "\n",
            "Output directory:  ./results/00013-new_image-mirror-stylegan2-kimg100-bgc-resumeffhq1024\n",
            "Training data:     ./datasets/new_image\n",
            "Training length:   100 kimg\n",
            "Resolution:        512\n",
            "Number of GPUs:    1\n",
            "\n",
            "Creating output directory...\n",
            "Loading training set...\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x5583509d0000 @  0x7f97f48ce001 0x7f97f1ad154f 0x7f97f1b21b58 0x7f97f1b25b17 0x7f97f1bc4203 0x558349a22544 0x558349a22240 0x558349a96627 0x558349a90ced 0x558349a2448c 0x558349a65159 0x558349a620a4 0x558349a22d49 0x558349a9694f 0x558349a909ee 0x558349962e2b 0x558349a92fe4 0x558349a909ee 0x558349962e2b 0x558349a92fe4 0x558349a90ced 0x558349962e2b 0x558349a92fe4 0x558349a23afa 0x558349a91915 0x558349a909ee 0x558349a906f3 0x558349b5a4c2 0x558349b5a83d 0x558349b5a6e6 0x558349b32163\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x558652342000 @  0x7f97f48cc1e7 0x7f97f1ad146e 0x7f97f1b21c7b 0x7f97f1b2235f 0x7f97f1bc4103 0x558349a22544 0x558349a22240 0x558349a96627 0x558349a909ee 0x558349a23bda 0x558349a92737 0x558349a909ee 0x558349a23bda 0x558349a92737 0x558349a909ee 0x558349a23bda 0x558349a92737 0x558349a23afa 0x558349a91915 0x558349a909ee 0x558349a23bda 0x558349a95d00 0x558349a909ee 0x558349a23bda 0x558349a92737 0x558349a90ced 0x558349a2448c 0x558349a65159 0x558349a620a4 0x558349a22d49 0x558349a9694f\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x558652342000 @  0x7f97f48cc1e7 0x7f97f1ad146e 0x7f97f1b21c7b 0x7f97f1b2235f 0x7f979d4d1235 0x7f979ce54792 0x7f979ce54d42 0x7f979ce0daee 0x558349a22437 0x558349a22240 0x558349a960f3 0x558349a23afa 0x558349a91c0d 0x558349a90ced 0x558349962eb0 0x558349a92fe4 0x558349a909ee 0x558349a23bda 0x558349a91c0d 0x558349a90ced 0x558349a23bda 0x558349a91c0d 0x558349a23afa 0x558349a91c0d 0x558349a909ee 0x558349a24271 0x558349a24698 0x558349a92fe4 0x558349a909ee 0x558349a23bda 0x558349a91915\n",
            "Image shape: [3, 512, 512]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n",
            "Resuming from \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/transfer-learning-source-nets/ffhq-res1024-mirror-stylegan2-noaug.pkl\"\n",
            "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/transfer-learning-source-nets/ffhq-res1024-mirror-stylegan2-noaug.pkl ... done\n",
            "\n",
            "G                             Params    OutputShape         WeightShape     \n",
            "---                           ---       ---                 ---             \n",
            "latents_in                    -         (?, 512)            -               \n",
            "labels_in                     -         (?, 0)              -               \n",
            "epochs                        1         ()                  ()              \n",
            "epochs_1                      1         ()                  ()              \n",
            "G_mapping/Normalize           -         (?, 512)            -               \n",
            "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense2              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense3              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense4              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense5              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense6              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense7              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Broadcast           -         (?, 16, 512)        -               \n",
            "dlatent_avg                   -         (512,)              -               \n",
            "Truncation/Lerp               -         (?, 16, 512)        -               \n",
            "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
            "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
            "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
            "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
            "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
            "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
            "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
            "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
            "G_synthesis/64x64/Conv0_up    2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Conv1       2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
            "G_synthesis/64x64/ToRGB       264195    (?, 3, 64, 64)      (1, 1, 512, 3)  \n",
            "G_synthesis/128x128/Conv0_up  1442561   (?, 256, 128, 128)  (3, 3, 512, 256)\n",
            "G_synthesis/128x128/Conv1     721409    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
            "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
            "G_synthesis/128x128/ToRGB     132099    (?, 3, 128, 128)    (1, 1, 256, 3)  \n",
            "G_synthesis/256x256/Conv0_up  426369    (?, 128, 256, 256)  (3, 3, 256, 128)\n",
            "G_synthesis/256x256/Conv1     213249    (?, 128, 256, 256)  (3, 3, 128, 128)\n",
            "G_synthesis/256x256/Upsample  -         (?, 3, 256, 256)    -               \n",
            "G_synthesis/256x256/ToRGB     66051     (?, 3, 256, 256)    (1, 1, 128, 3)  \n",
            "G_synthesis/512x512/Conv0_up  139457    (?, 64, 512, 512)   (3, 3, 128, 64) \n",
            "G_synthesis/512x512/Conv1     69761     (?, 64, 512, 512)   (3, 3, 64, 64)  \n",
            "G_synthesis/512x512/Upsample  -         (?, 3, 512, 512)    -               \n",
            "G_synthesis/512x512/ToRGB     33027     (?, 3, 512, 512)    (1, 1, 64, 3)   \n",
            "---                           ---       ---                 ---             \n",
            "Total                         30276585                                      \n",
            "\n",
            "\n",
            "D                    Params    OutputShape         WeightShape     \n",
            "---                  ---       ---                 ---             \n",
            "images_in            -         (?, 3, 512, 512)    -               \n",
            "labels_in            -         (?, 0)              -               \n",
            "512x512/FromRGB      256       (?, 64, 512, 512)   (1, 1, 3, 64)   \n",
            "512x512/Conv0        36928     (?, 64, 512, 512)   (3, 3, 64, 64)  \n",
            "512x512/Conv1_down   73856     (?, 128, 256, 256)  (3, 3, 64, 128) \n",
            "512x512/Skip         8192      (?, 128, 256, 256)  (1, 1, 64, 128) \n",
            "256x256/Conv0        147584    (?, 128, 256, 256)  (3, 3, 128, 128)\n",
            "256x256/Conv1_down   295168    (?, 256, 128, 128)  (3, 3, 128, 256)\n",
            "256x256/Skip         32768     (?, 256, 128, 128)  (1, 1, 128, 256)\n",
            "128x128/Conv0        590080    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
            "128x128/Conv1_down   1180160   (?, 512, 64, 64)    (3, 3, 256, 512)\n",
            "128x128/Skip         131072    (?, 512, 64, 64)    (1, 1, 256, 512)\n",
            "64x64/Conv0          2359808   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "64x64/Conv1_down     2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "64x64/Skip           262144    (?, 512, 32, 32)    (1, 1, 512, 512)\n",
            "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
            "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
            "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
            "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
            "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
            "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
            "Output               513       (?, 1)              (512, 1)        \n",
            "---                  ---       ---                 ---             \n",
            "Total                28982849                                      \n",
            "\n",
            "Exporting sample images...\n",
            "Replicating networks across 1 GPUs...\n",
            "Initializing augmentations...\n",
            "Setting up optimizers...\n",
            "Constructing training graph...\n",
            "Finalizing training ops...\n",
            "Initializing metrics...\n",
            "Training for 100 kimg...\n",
            "\n",
            "tick 0     kimg 0.1      time 2m 02s       sec/tick 55.5    sec/kimg 433.29  maintenance 66.9   gpumem 7.1   augment 0.000\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 645, in <module>\n",
            "    main()\n",
            "  File \"train.py\", line 637, in main\n",
            "    run_training(**vars(args))\n",
            "  File \"train.py\", line 522, in run_training\n",
            "    training_loop.training_loop(**training_options)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1zQGyqDeW63FEr3sXvFz23SVnqvoGEBUd/AIB_04_Stylebot/colab-sg2-ada/stylegan2-ada/training/training_loop.py\", line 262, in training_loop\n",
            "    tflib.run(G_train_op)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1zQGyqDeW63FEr3sXvFz23SVnqvoGEBUd/AIB_04_Stylebot/colab-sg2-ada/stylegan2-ada/dnnlib/tflib/tfutil.py\", line 33, in run\n",
            "    return tf.get_default_session().run(*args, **kwargs)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 956, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
            "    target_list, run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyjDor9ern0G"
      },
      "source": [
        "## Generator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekTD-s5OIApP"
      },
      "source": [
        "# 1024해상도의 200kimg 학습된 이미지의 pkl파일\n",
        "network = './network-snapshot-000200.pkl'\n",
        "\n",
        "#생성된 이미지 seed 확인인--create-grid\n",
        "# !python generate.py generate-images --trunc=0.5 --seeds=0-45 --create-grid  --network={network} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR7zyw0asIEw"
      },
      "source": [
        "# interpolation\n",
        "!python generate.py generate-latent-walk --trunc=0.5 --seeds=0-45 --create-grid  --network={network} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGjI57FQr0E0"
      },
      "source": [
        "## Style Mixing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1QhJ03ySerC",
        "outputId": "1665d9a1-f81d-44bd-cf88-27d0dc8d1d13"
      },
      "source": [
        "!python style_mixing.py --trunc=0.5 --rows=14,1000,1022,1080,1086,42994967295 --cols=23,1004,1043,30,1048  --network='./network-snapshot-000200.pkl' --styles=0-3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading networks from \"/content/drive/MyDrive/AIB_04_Stylebot/network-snapshot-000100.pkl\"...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n",
            "Generating W vectors...\n",
            "Generating images...\n",
            "Generating style-mixed images...\n",
            "Saving images...\n",
            "Saving image grid...\n"
          ]
        }
      ]
    }
  ]
}